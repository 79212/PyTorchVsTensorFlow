{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepatation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import the necessary standard libraries, load in the data from a csv file, and set some variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>352686</th>\n",
       "      <td>1</td>\n",
       "      <td>@BellsCullen1901 hey i may not be right. dont ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276608</th>\n",
       "      <td>1</td>\n",
       "      <td>follow jesszlatos here on twitter!!! please?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392841</th>\n",
       "      <td>1</td>\n",
       "      <td>FORGET FUN FUCK FEAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367683</th>\n",
       "      <td>1</td>\n",
       "      <td>@CzarinaE i agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138535</th>\n",
       "      <td>0</td>\n",
       "      <td>i hate my sleeping patterns .. i can never go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>0</td>\n",
       "      <td>@MonaSmith sadly, yes. i think i need councili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315240</th>\n",
       "      <td>1</td>\n",
       "      <td>HMV Shinjuku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306734</th>\n",
       "      <td>1</td>\n",
       "      <td>Office til around 6 today. Good day yesterday....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372272</th>\n",
       "      <td>1</td>\n",
       "      <td>Felt one of the longest (yet gentlest) earthqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144809</th>\n",
       "      <td>0</td>\n",
       "      <td>@DianeMorgan00 lovely, but undressable   I'm t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiments                                             tweets\n",
       "352686           1  @BellsCullen1901 hey i may not be right. dont ...\n",
       "276608           1      follow jesszlatos here on twitter!!! please? \n",
       "392841           1                              FORGET FUN FUCK FEAR \n",
       "367683           1                                 @CzarinaE i agree \n",
       "138535           0  i hate my sleeping patterns .. i can never go ...\n",
       "852              0  @MonaSmith sadly, yes. i think i need councili...\n",
       "315240           1                                      HMV Shinjuku \n",
       "306734           1  Office til around 6 today. Good day yesterday....\n",
       "372272           1  Felt one of the longest (yet gentlest) earthqu...\n",
       "144809           0  @DianeMorgan00 lovely, but undressable   I'm t..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading data from csv file\n",
    "\n",
    "data_path = './data/tweets.csv'\n",
    "\n",
    "data = pd.read_csv(data_path, usecols=[0,5], encoding='utf-8', names=['sentiments', 'tweets'])\n",
    "data = data.sample(frac=.10)  # shuffle the tweets\n",
    "\n",
    "data.sentiments = [0 if x==0 else 1 for x in data.sentiments]  # \n",
    "data[:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@BellsCullen1901 hey i may not be right. dont ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>follow jesszlatos here on twitter!!! please?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>FORGET FUN FUCK FEAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>@CzarinaE i agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i hate my sleeping patterns .. i can never go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>@MonaSmith sadly, yes. i think i need councili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>HMV Shinjuku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Office til around 6 today. Good day yesterday....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Felt one of the longest (yet gentlest) earthqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>@DianeMorgan00 lovely, but undressable   I'm t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiments                                             tweets\n",
       "0           1  @BellsCullen1901 hey i may not be right. dont ...\n",
       "1           1      follow jesszlatos here on twitter!!! please? \n",
       "2           1                              FORGET FUN FUCK FEAR \n",
       "3           1                                 @CzarinaE i agree \n",
       "4           0  i hate my sleeping patterns .. i can never go ...\n",
       "5           0  @MonaSmith sadly, yes. i think i need councili...\n",
       "6           1                                      HMV Shinjuku \n",
       "7           1  Office til around 6 today. Good day yesterday....\n",
       "8           1  Felt one of the longest (yet gentlest) earthqu...\n",
       "9           0  @DianeMorgan00 lovely, but undressable   I'm t..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_path = \"./data/tweets_short.csv\"\n",
    "\n",
    "data.to_csv(new_data_path, header=True, index=False, encoding='utf-8')\n",
    "data = pd.read_csv(new_data_path, encoding='utf-8')\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting some variables\n",
    "\n",
    "vocab_size = 20000\n",
    "maxlen = 42\n",
    "batch_size = 32\n",
    "embedding_dim = 25\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 2.0 & Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use Keras' tokenizer for this example. The goal is to turn each tweet into an array of integers, with each integer representing one word of the vocabulary. In addition, we must pad shorter arrays so that they all have uniform length. That makes it easier to process them in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instatiate keras tokenizer\n",
    "tokenizer = Tokenizer(vocab_size, oov_token='<00v>')\n",
    "tokenizer.fit_on_texts(data.tweets)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(data.tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding the sequences so that they have unoform dimension\n",
    "\n",
    "padded = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=maxlen)\n",
    "padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = padded\n",
    "y_data = np.array(data.sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(dict(data))\n",
    "\n",
    "for feature_batch in dataset.take(1):\n",
    "    for key, value in feature_batch.items():\n",
    "        print(\"  {!r:20s}: {}\".format(key, value))\n",
    "        \n",
    "\n",
    "dataset = tf.data.experimental.make_csv_dataset(data_path, batch_size=32, header=False, select_columns=[0,5])\n",
    "\n",
    "for feature_batch in dataset.take(1):\n",
    "    for key, value in feature_batch.items():\n",
    "        print(\"  {!r:20s}: {}\".format(key, value))\n",
    "        \n",
    "dataset = dataset.map(lambda *items: tokenizer.texts_to_sequences(items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is a simple two-layer neural network with an additional embedding layer. In Keras, the input dimension need not be determined, the model.compile() method is able to figure that out by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 42, 25)            500000    \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1050)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               134528    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 634,657\n",
      "Trainable params: 634,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# with Keras Sequential API\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=maxlen, mask_zero=True),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=X_data, y=y_data, batch_size=batch_size, epochs=epochs, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"subclass__model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     multiple                  500000    \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             multiple                  3328      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             multiple                  129       \n",
      "=================================================================\n",
      "Total params: 503,457\n",
      "Trainable params: 503,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# with Keras' Subclassing API\n",
    "\n",
    "class Subclass_Model(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, embedding_dim=25):\n",
    "        \n",
    "        super(Subclass_Model, self).__init__()\n",
    "        self.embedding_layer = tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=maxlen, mask_zero=True)\n",
    "        self.flatten_layer = tf.keras.layers.Flatten()\n",
    "        self.fc1_layer =  tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.fc2_layer =  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        x = self.embedding_layer(inputs)\n",
    "        x = self.flatten_layer(x)\n",
    "        x = self.fc1_layer(x)\n",
    "        return self.fc2_layer(x)\n",
    "        \n",
    "model = Subclass_Model()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "model.build((42,))  # must be called in this case to print a summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 42)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 42, 25)            500000    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1050)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               134528    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 634,657\n",
      "Trainable params: 634,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# with Keras Functional API\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(42,))\n",
    "x = tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=maxlen, mask_zero=True)(inputs)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=X_data,\n",
    "          y=y_data,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          verbose=2,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=False, show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# fitting the model\n",
    "\n",
    "model.fit(x=X_data, y=y_data, batch_size=batch_size, epochs=epochs, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting some variables\n",
    "\n",
    "vocab_size = 20000\n",
    "maxlen = 42\n",
    "batch_size = 32\n",
    "embedding_dim = 25\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = torch.LongTensor(padded)\n",
    "y_data = torch.FloatTensor(np.array(data.sentiments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch does not have a fit method like TensorFlow, which is why you need to build the training loop yourself. This is less of a worry than it sounds.\n",
    "\n",
    "You also need to create a way to process data in batches, which is best done by creating a custom PyTorch's Dataset and pass it to the DataLoader function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, tweets, sentiments):\n",
    "        self.tweets = tweets\n",
    "        self.sentiments = sentiments\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        sample = {\"tweets\":self.tweets[index,:], \"sentiments\":self.sentiments[index]}\n",
    "        \n",
    "        return sample\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.tweets.shape[0]\n",
    "    \n",
    "    \n",
    "tweets_dataset = MyDataset(X_data, y_data)\n",
    "\n",
    "dataloader = DataLoader(tweets_dataset, batch_size=batch_size,\n",
    "                        shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a neural network in PyTorch is very similar to TensorFlow. The nn.sequential method is helpful if you want to create a rather simple standard architecture. Unlike TensorFlow, you need to specify the input dimensions of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with PyTorch nn.Sequential\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Embedding(vocab_size, embedding_dim),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(maxlen*embedding_dim, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with PyTorch Subclassing\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_dim=25):\n",
    "        super(Model, self).__init__()\n",
    "        self.embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.flatten_layer = nn.Flatten()\n",
    "        self.fc1_layer = nn.Linear(maxlen*embedding_dim, 128)\n",
    "        self.fc2_layer = nn.Linear(128,1)\n",
    "        \n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        x = self.embedding_layer(inputs)\n",
    "        x = self.flatten_layer(x)\n",
    "        x = F.relu(self.fc1_layer(x))\n",
    "        \n",
    "        return torch.sigmoid(self.fc2_layer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, dataloader, epochs=5):\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "    \n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for sample in dataloader:\n",
    "\n",
    "            X = sample[\"tweets\"]\n",
    "            y = sample[\"sentiments\"]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            out = model(X)\n",
    "            loss = criterion(out, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        print(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model = Model()\n",
    "\n",
    "fit(model, dataloader, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with CNN tbd\n",
    "\n",
    "embedding_dim = 64\n",
    "max_seq_len = 46\n",
    "vocab_size = 20000\n",
    "n_filters = 128\n",
    "kernel_size = 5\n",
    "batch_size = 32\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Embedding(vocab_size, embedding_dim),\n",
    "    nn.Conv1d(max_seq_len, embedding_dim, kernel_size),\n",
    "    nn.MaxPool1d(46), \n",
    "    nn.Linear(46, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
